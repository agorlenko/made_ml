{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465e94f2-e039-495a-9983-9e4e194520bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from nltk import bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e445ca57-58d6-4638-be11-dd6ce0116f8e",
   "metadata": {},
   "source": [
    "В качестве корпуса будем использовать русский текст \"Войны и мира\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a7abad4-7009-4798-8949-33f5f7b69a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = None\n",
    "with open('corpora/WarAndPeace.txt', mode='r') as f:\n",
    "    corpus = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b90fe68-8c8c-40a6-b11f-314232bdbe85",
   "metadata": {},
   "source": [
    "В качестве препроцессинга приведем текст к нижнему регистру и удалим знаки препинания и т.п., оставив пробелы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5a85337-e6eb-499b-b64d-989397c7c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return re.sub('[!\\–\"#$%&\\'\\(\\)\\*\\+,\\./:;<=>\\?@\\[\\\\]\\^_`{|}\\~]', '', text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9c01efe-1188-4d1b-bef0-d0a0b3ce8655",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = preprocess_text(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71662b53-0502-4e88-9622-0b746ea04a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'annotation\\n\\n\\n\\tвойна и мир  самый известный роман льва николаевича толстого как никакое другое произведение писателя отражает глубину его мироощущения и философии\\tэта книга из разряда вечных потому что она обо всем  о жизни и смерти о любви и чести о мужестве и героизме о славе и подвиге о войне и мире\\tпервый том знакомит с высшим обществом россии xix века показаны взаимоотношения между родителями и детьми в семье ростовых сватовство у болконских интриги у безуховых вечера в салоне фрейлины апшер'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac73b09-0b85-48fe-a68b-6c41f61bd9b5",
   "metadata": {},
   "source": [
    "Тогда наш алфавит - это множество букв, встречающихся в корпусе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7191f49d-9099-4898-b892-beb437199aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = sorted(list(set(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b69ed2b-d4e6-4816-9f8c-946523a9a0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = '''Уинстон направился к лестнице. К лифту не стоило и подходить. Он даже в лучшие времена редко работал, \n",
    "а теперь, в дневное время, электричество вообще отключали. Действовал режим экономии — готовились к Неделе ненависти. \n",
    "Уинстону предстояло одолеть семь маршей; ему шел сороковой год, над щиколоткой у него была варикозная язва: \n",
    "он поднимался медленно и несколько раз останавливался передохнуть. На каждой площадке со стены глядело все то же лицо. \n",
    "Портрет был выполнен так, что, куда бы ты ни стал, глаза тебя не отпускали.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31468155-4500-4ebb-8b2f-e9064b2a3e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "уинстон направился к лестнице к лифту не стоило и подходить он даже в лучшие времена редко работал \n",
      "а теперь в дневное время электричество вообще отключали действовал режим экономии — готовились к неделе ненависти \n",
      "уинстону предстояло одолеть семь маршей ему шел сороковой год над щиколоткой у него была варикозная язва \n",
      "он поднимался медленно и несколько раз останавливался передохнуть на каждой площадке со стены глядело все то же лицо \n",
      "портрет был выполнен так что куда бы ты ни стал глаза тебя не отпускали\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_text = preprocess_text(example_text)\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca9cb03-aad2-4401-8430-931fd37252ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb97d6b-6669-44e1-9322-b25169173b78",
   "metadata": {},
   "source": [
    "Сопоставим алфавиту его случайную перестановку. С помощью данной перестановки закодируем текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c19a269-3b76-4c41-8c43-a002d4c3eebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "зеéёгщéüéабsаûе»ёъüьü»уёгéеpуüьü»ечгзüéуüёгще»щüеüбщíxщíегэüщéüíаçуüûü»з\n",
      "ôеуüûsувуéаüsуíьщüsа…щга»üiаüгубуsэüûüíéуûéщуüûsувъüт»уьгsе\n",
      "уёгûщüûщщ…hуüщгь»ю\n",
      "а»еüíу„ёгûщûа»üsуçевüтьщéщвееüдüâщгщûе»еёэüьüéуíу»уüéуéаûеёгеüiзеéёгщéзüбsуíёгщъ»щüщíщ»угэüёувэüваsôу„üувзüôу»üёщsщьщûщ„üâщíüéаíühеьщ»щгьщ„üзüéуâщü…j»аüûаsеьщиéаъüъиûаüiщéüбщíéева»ёъüвуí»уééщüеüéуёьщ»эьщüsаиüщёгаéаû»еûа»ёъüбуsуíщxéзгэüéаüьаçíщ„üб»щhаíьуüёщüёгуéjüâ»ъíу»щüûёуüгщüçуü»еpщüiбщsгsугü…j»üûjбщ»éуéüгаьü\n",
      "гщüьзíаü…jüгjüéеüёга»üâ»аиаüгу…ъüéуüщгбзёьа»еi\n"
     ]
    }
   ],
   "source": [
    "mapping = {u: v for u, v in zip(alphabet, np.random.permutation(alphabet))}\n",
    "encoded_text = ''.join(mapping[u] for u in example_text)\n",
    "    \n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb3c4d-7119-44b8-acd8-652ec583b5f0",
   "metadata": {},
   "source": [
    "Для того, чтобы раскодировать текст, посчитаем частоты букв по закодированному тексту и сопоставим буквы по частоте с данными, посчитанными по корпусу. Т.е. самая частая буква в корпусе будет соответствовать самой частой в закодированном тексте и т.д.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2af3745-e656-4dc3-af45-8b15e68f1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_freq = Counter(corpus).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "409a7ee5-65b8-4be4-ab5a-1e3f4c74222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(encoded_text, corpus_freq):\n",
    "    encoded_text_freq = Counter(encoded_text).most_common()\n",
    "    mapping = {example_freq[0]: corpus_freq[0] \n",
    "               for example_freq, corpus_freq in zip(encoded_text_freq, corpus_freq)}\n",
    "    return ''.join(mapping[symbol] for symbol in encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "679c3094-00ba-4c9e-9868-00018202d192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "мселтое енуднвсилп р иалтесeа р исцтм еа лтосио с уок—окстг ое кн\n",
      "а в имйшса вдаяаен дакро дньотни зн тауадг в кеавеоа вдаяп юиартдсйалтво вооьха отриnйнис каблтвовни да\n",
      "ся юроеоясс s чотовсислг р еакаиа еаенвслтс змселтоем удаклтопио окоиатг лаяг яндшаб аям шаи лодоровоб чок енк хсроиотроб м еачо ьыин вндсроженп пжвн зое уокесянилп яакиаеео с еалроигро днж олтненвисвнилп уадако—емтг ен рн\n",
      "коб уиохнкра ло лтаеы чипкаио вла то \n",
      "а исeо зуодтдат ьыи выуоиеае тнр йто рмкн ьы ты ес лтни чинжн таьп еа отумлрнисз\n"
     ]
    }
   ],
   "source": [
    "decoded_text = decode(encoded_text, corpus_freq)\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6241a-6680-4076-99e7-130f191f1c8a",
   "metadata": {},
   "source": [
    "В качестве метрики качества возьмем просто долю правильно отгаданных букв:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a4eea3e-be17-4c34-8fd2-34d6258cbf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality(original_text, decoded_text):\n",
    "    n_success = 0\n",
    "    for i in range(len(original_text)):\n",
    "        if original_text[i] == decoded_text[i]:\n",
    "            n_success += 1\n",
    "    return n_success / len(original_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d18f5634-a063-4321-a9d7-ec9a4673d466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3659491193737769"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality(example_text, decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad205f9-4ccf-475e-aeba-3f0f20fcea89",
   "metadata": {},
   "source": [
    "С биграммами поступим аналогично: посчитаем частоты биграмм по корпусу и по тексту, а далее сопоставим их в отсордированном по убыванию частоты порядке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb352a34-f200-47ae-9cfe-82992e95af0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bigrams = Counter(bigrams(corpus)).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66e0707a-1dae-4a1e-af45-a4d76380aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_bigrams(encoded_text, corpus_bigrams):\n",
    "    encoded_text_freq = Counter(bigrams(encoded_text)).most_common()\n",
    "    mapping = {''.join(example_freq[0]): ''.join(corpus_freq[0]) \n",
    "               for example_freq, corpus_freq in zip(encoded_text_freq, corpus_bigrams)}\n",
    "    \n",
    "    decoded_text = ''\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(encoded_text):\n",
    "        current_bigram = encoded_text[i: i + 2]\n",
    "        if len(current_bigram) == 2:\n",
    "            result_bigram = mapping[current_bigram]\n",
    "            decoded_text += result_bigram\n",
    "        else:\n",
    "            result_bigram = mapping[encoded_text[-2] + encoded_text[-1]]\n",
    "            decoded_text += result_bigram[1]\n",
    "        i += 2\n",
    "    \n",
    "    return decoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4034488e-7b25-42d7-99d6-ff1e203a739a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "атте нвотоодорв ренеерпрсят а ростс  де на нв о ь олннкоисгоал\n",
      "\n",
      "н а веаядиар п о зто тка в тамй  кния зааз\n",
      "— п\n",
      "\n",
      "е ивки п осо упоедассли —  пейхоа й муше кь ричажеан к тадбы у вташиь ля ч ну стидне ска га е тоу и ь своги ал додкаи ихноовилпо мнаенгоесизойиксидн гнаегs антьотко ссьдуитлай  вли де  чомвия осас вязкузнуля ымвоол ебы крелькапорыо ь е ю лаийо лосаутонтоятша крера —калсмо м ся ружатьраноошдаа тиназавшотугрино пмим о  рерт о брегемдоомви ппалае воонро хо мндеомскжи сь и  котинькм зь ие овцеывруст \n"
     ]
    }
   ],
   "source": [
    "decoded_text_with_bigrams = decode_bigrams(encoded_text, corpus_bigrams)\n",
    "print(decoded_text_with_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "237bdda8-437e-488f-8dc9-27a3ac6f02fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10763209393346379"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality(example_text, decoded_text_with_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498ee1bc-e46d-482c-82b5-b7275737baf4",
   "metadata": {},
   "source": [
    "Видим, что с биграммами получилось даже хуже, чем с отдельными символами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd8bafa-ed54-46fe-aac6-60dec7e54718",
   "metadata": {},
   "source": [
    "Для того, чтобы улучшить результаты, попробуем использовать алгоритм Метрополиса-Гастингса. Ключ шифрования у нас по сути - это перестановка алфавита. Тогда на каждом шаге алгоритма мы будем рассматривать новый ключ, как случайную перестановку двух символов из старого (а начнем просто с тождественной перестановки). Тогда с помощью данного ключа мы попробуем расшифровать текст и посчитать для расшифрованного текста функцию правдоподобия, сравнив ее со старой и, исходя из этого, решая принимать новый ключ или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b02db7f3-5962-4535-b7c4-238db3696031",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = sum(v for k, v in corpus_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "314adfb4-c3a5-49ed-9b6b-3f150c2dc8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bigrams_dict = {k: v for k, v in corpus_bigrams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d9c6c38-36e0-4582-89d6-526a023cee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 10 ** -6\n",
    "\n",
    "def likelihood_log(text, corpus_bigrams_dict, total_count):\n",
    "    result = 0\n",
    "    for cur_bigram in bigrams(text):\n",
    "        result += np.log(corpus_bigrams_dict.get(cur_bigram, EPS) / total_count)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e12e4df3-ca1f-46d3-aad6-21d8d7825f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings_log_accept(l, l_new):\n",
    "    if l_new > l:\n",
    "        return True\n",
    "    else:\n",
    "        return (np.random.rand() < (np.exp(l_new - l)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "929eb164-9ec1-4133-897d-75a52a96580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metropolis_hastings(encoded_text, n_iter=1000, log_step=100):\n",
    "    \n",
    "    current_key = alphabet.copy()\n",
    "    \n",
    "    current_text = encoded_text\n",
    "    current_likelihood = likelihood_log(current_text, corpus_bigrams_dict, total_count)\n",
    "        \n",
    "    for step in range(n_iter):\n",
    "        \n",
    "        i, j = np.random.choice(len(current_key), 2, replace=False)\n",
    "        current_key[i], current_key[j] = current_key[j], current_key[i]\n",
    "        \n",
    "        mapping = {u: v for u, v in zip(current_key, alphabet)}\n",
    "        \n",
    "        new_text = ''.join(mapping[u] for u in encoded_text)\n",
    "                \n",
    "        if current_text != new_text:\n",
    "            new_likelihood = likelihood_log(new_text, corpus_bigrams_dict, total_count)\n",
    "\n",
    "            if metropolis_hastings_log_accept(current_likelihood, new_likelihood):\n",
    "                current_text = new_text\n",
    "                current_likelihood = new_likelihood\n",
    "            else:\n",
    "                current_key[i], current_key[j] = current_key[j], current_key[i]\n",
    "        else:\n",
    "            current_key[i], current_key[j] = current_key[j], current_key[i]\n",
    "            \n",
    "        if (step + 1) % log_step == 0:\n",
    "            print(current_text)\n",
    "            print(f'step: {step + 1}, likelihood = {current_likelihood}')\n",
    "            print('')\n",
    "        \n",
    "    return current_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f895f0df-0b8b-4ab4-a904-dd328bc5af81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ьинстон накравимсю л местнице л ми…ть не стоимо и код\n",
      "одиты он даже в мьшфие врезена редло раготам па текеры в дневное врезю ямелтришество воогче отлм-шами действовам режиз ялонозии — ботовимисы л недеме ненависти пьинстонь кредстоюмо одометы сезы зарфей езь фем сороловой бод над чиломотлой ь небо гума варилохнаю юхва пон коднизамсю зедменно и несломыло рах останавмивамсю кередо\n",
      "ньты на лаждой кмочадле со стену бмюдемо все то же мицо пкортрет гум вукомнен тал што льда гу ту ни стам бмаха тегю не откьсламип\n",
      "step: 10000, likelihood = -3080.409574597824\n",
      "\n",
      "ьинстон направился м лестнице м ли-ть не стоило и под\n",
      "одиты он даже в льчшие врезена редмо ракотал ба теперы в дневное врезя юлемтричество воокфе отмл…чали действовал режиз юмонозии — готовилисы м неделе ненависти бьинстонь предстояло одолеты сезы заршей езь шел соромовой год над фимолотмой ь него кула варимохная яхва бон поднизался зедленно и несмолымо рах останавливался передо\n",
      "ньты на маждой плофадме со стену глядело все то же лицо бпортрет кул вуполнен там что мьда ку ту ни стал глаха текя не отпьсмалиб\n",
      "step: 20000, likelihood = -3015.5829427189205\n",
      "\n",
      "ьинстон направился к лестнице к ли-ть не стоило и пом\n",
      "омиту он мафе в льчшие врезена ремко работал да теперу в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовилису к немеле ненависти дьинстонь премстояло омолету сезу заршей езь шел сороковой гом нам жиколоткой ь него была варикохная яхва дон помнизался земленно и несколуко рах останавливался перемо\n",
      "ньту на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кьма бы ты ни стал глаха тебя не отпьскалид\n",
      "step: 30000, likelihood = -2946.843519229287\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 40000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 50000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 60000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 70000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли\n",
      "ту не стоило и пом-омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо-нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 80000, likelihood = -2909.9287739074807\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии e готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 90000, likelihood = -2910.6039527241073\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 100000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 110000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к лиюту не стоило и пом-омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже откл\n",
      "чали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо-нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 120000, likelihood = -2910.1221208558877\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 130000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии n готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 140000, likelihood = -2912.229400683987\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 150000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 160000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 170000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 180000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 190000, likelihood = -2907.729711601131\n",
      "\n",
      "уинстон направился к лестнице к ли-ту не стоило и пом\n",
      "омить он мафе в лучшие врезена ремко работал да теперь в мневное врезя электричество вообже отключали мействовал рефиз эконозии — готовились к немеле ненависти дуинстону премстояло омолеть сезь заршей езу шел сороковой гом нам жиколоткой у него была варикохная яхва дон помнизался земленно и несколько рах останавливался перемо\n",
      "нуть на кафмой пложамке со стены глямело все то фе лицо дпортрет был выполнен так что кума бы ты ни стал глаха тебя не отпускалид\n",
      "step: 200000, likelihood = -2907.729711601131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_mcmc = metropolis_hastings(encoded_text, n_iter=200000, log_step=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14e4dcc1-1a52-444c-b33b-e5dd7e16eda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9099804305283757"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality(example_text, decoded_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a415c0-e39f-438e-b1aa-8b02c469d35f",
   "metadata": {},
   "source": [
    "Видим, что количество правильно отгаданных букв значительно выросло, и сообщение уже читается."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7ac80d-23c6-413d-821a-c4a8d348a3e4",
   "metadata": {},
   "source": [
    "Теперь попробуем расшифровать сообщение из задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4336d2f6-2abb-443f-bf32-d6aa96f4bf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_message = 'დჳჵჂႨშႼႨშჂხჂჲდႨსႹႭჾႣჵისႼჰႨჂჵჂႨႲႹႧჲჂႨსႹႭჾႣჵისႼჰႨჲდႩჳჲႨჇႨႠჲႹქႹႨჳႹႹჱჶდსჂႽႨႩႹჲႹႭႼჰႨჵდქႩႹႨႲႭႹႧჂჲႣჲიႨჳႩႹႭდდႨშჳდქႹႨშႼႨშჳდႨჳხდჵႣჵჂႨႲႭႣშჂჵისႹႨჂႨႲႹჵჇႧჂჲდႨჾႣႩჳჂჾႣჵისႼჰႨჱႣჵჵႨეႣႨႲႹჳჵდხსდდႨႧდჲშდႭჲႹდႨეႣხႣსჂდႨႩჇႭჳႣႨႾႹჲႽႨႩႹსდႧსႹႨႽႨსჂႧდქႹႨსდႨႹჱდჶႣნ'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7368e7cd-c946-4054-a882-13e7dcd0ec5d",
   "metadata": {},
   "source": [
    "Тут возникает проблема: символов из сообщения нет в нашем алфавите. И если напрямую попытаться расшифровать это сообщение, то ничего не получится. Чтобы решить эту проблему, просто возьмем случайную выборку из алфавита корпуса размером равную количеству различных букв сообщения и каждой букве сообщения поставим в соответствие букву алфавита. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59251441-5acf-4254-93c1-2450ed2b216c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g6ôзфqâфqзгз„gфеl«wvôмеâкфзôзф2lб„зфеl«wvôмеâкф„gи6„фсфо„lшlф6llçпgезoфиl„l«âкфôgшиlф2«lбз„v„мф6иl«ggфq6gшlфqâфq6gф6гgôvôзф2«vqзôмеlфзф2lôсбз„gфwvи6зwvôмеâкфçvôôф—vф2l6ôgгеggфбg„qg«„lgф—vгvезgфис«6vфel„oфиlеgбеlфoфезбgшlфеgфlçgпvj\n"
     ]
    }
   ],
   "source": [
    "secret_message_alphabet = sorted(set(list(secret_message)))\n",
    "\n",
    "secret_message_mapping = {u: v \n",
    "                          for u, v in zip(secret_message_alphabet, \n",
    "                                          np.random.choice(alphabet, len(secret_message_alphabet), replace=False))}\n",
    "\n",
    "secret_message_in_corpus_alphabet = ''.join(secret_message_mapping[u] for u in secret_message)\n",
    "print(secret_message_in_corpus_alphabet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67e79c38-d856-419a-a8a7-9c4c5b2f121a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "осли вы вимидо неркальный или пегди неркальный дотсд у ждече сеебхония тедерый лочте прегидадь стероо всоче вы всо смолали правильне и пелугидо катсикальный балл за песломноо годвордео заманио турса шедя теногне я нигоче но ебохаю\n",
      "step: 50000, likelihood = -1298.5809624366318\n",
      "\n",
      "осли вы вимидо неркальный или пегди неркальный дотсд у ждече сеебхония тедерый лочте прегидадь стероо всоче вы всо смолали правильне и пелугидо катсикальный балл за песломноо годвордео заманио турса цедя теногне я нигоче но ебоха-\n",
      "step: 100000, likelihood = -1302.5899995956327\n",
      "\n",
      "исло вы вомоди неркальный оло пегдо неркальный дитсд у ждече сеебхиноя тедерый личте прегодадь стерии всиче вы вси смилало правольне о пелугоди катсокальный балл за песлимнии гидвирдеи заманои турса шедя тенигне я ногиче ни ебихаю\n",
      "step: 150000, likelihood = -1302.0740595136062\n",
      "\n",
      "осли вы викидо нерзальный или пегди нерзальный дотсд у ждеше сеехмония тедерый лоште прегидадь стероо всоше вы всо сколали правильне и пелугидо затсизальный халл ча песлокноо годвордео чаканио турса бедя теногне я нигоше но ехомац\n",
      "step: 200000, likelihood = -1306.4243556388983\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у юдого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл за послемнее жедвердое замание турса ходя тонежно я нижего не обещаш\n",
      "step: 250000, likelihood = -1289.3260553440434\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у юдого сообчения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл за послемнее жедвердое замание турса ходя тонежно я нижего не обеча\n",
      "\n",
      "step: 300000, likelihood = -1288.8124928625973\n",
      "\n",
      "ести вы вичиде норкатьный ити пожди норкатьный делсд у здого сообщения лодорый тегло прожидадь слорее всего вы все счетати правитьно и потужиде калсикатьный батт ма постечнее жедвердое мачание лурса ходя лонежно я нижего не обещаш\n",
      "step: 350000, likelihood = -1294.3605671828884\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у юдого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл за послемнее жедвердое замание турса ходя тонежно я нижего не обещач\n",
      "step: 400000, likelihood = -1289.6121335669131\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у эдого сообчения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл за послемнее жедвердое замание турса ходя тонежно я нижего не обеча\n",
      "\n",
      "step: 450000, likelihood = -1290.4684915562439\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обеща-\n",
      "step: 500000, likelihood = -1288.199169283369\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обещаш\n",
      "step: 550000, likelihood = -1285.8589673268036\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обещаш\n",
      "step: 600000, likelihood = -1285.8589673268036\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого соочшения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный чалл ба послемнее жедвердое бамание турса ходя тонежно я нижего не очеша\n",
      "\n",
      "step: 650000, likelihood = -1286.8137590963458\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обещаш\n",
      "step: 700000, likelihood = -1285.8589673268036\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обещаш\n",
      "step: 750000, likelihood = -1285.8589673268036\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса шодя тонежно я нижего не обеща\n",
      "\n",
      "step: 800000, likelihood = -1288.4158380548665\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обеща…\n",
      "step: 850000, likelihood = -1288.016847726575\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обеща\n",
      "\n",
      "step: 900000, likelihood = -1286.3586196499714\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого соочшения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный чалл ба послемнее жедвердое бамание турса ходя тонежно я нижего не очеша\n",
      "\n",
      "step: 950000, likelihood = -1286.8137590963458\n",
      "\n",
      "если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обещац\n",
      "step: 1000000, likelihood = -1288.2861806603587\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'если вы вимиде норкальный или пожди норкальный детсд у здого сообщения тодорый легто прожидадь сторее всего вы все смелали правильно и полужиде катсикальный балл ча послемнее жедвердое чамание турса ходя тонежно я нижего не обещац'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metropolis_hastings(secret_message_in_corpus_alphabet, n_iter=1000000, log_step=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11902b4-2d93-41ed-8136-65a1f6a11480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
